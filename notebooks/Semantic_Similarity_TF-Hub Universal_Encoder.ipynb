{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUymE2l9GZfO"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Hub Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "JMyTNwSJGGWg"
   },
   "outputs": [],
   "source": [
    "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "co7MV6sX7Xto"
   },
   "source": [
    "# Universal Sentence Encoder\n",
    "\n",
    "\n",
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "</td></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAVQGidpL8v5"
   },
   "source": [
    "This notebook illustrates how to access the Universal Sentence Encoder and use it for sentence similarity and sentence classification tasks.\n",
    "\n",
    "The Universal Sentence Encoder makes getting sentence level embeddings as easy as it has historically been to lookup the embeddings for individual words. The sentence embeddings can then be trivially used to compute sentence level meaning similarity as well as to enable better performance on downstream classification tasks using less supervised training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOTzp8O36CyQ"
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lVjNK8shFKOC"
   },
   "outputs": [],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet tensorflow-hub\n",
    "!pip3 install --quiet seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63Pd3nJnTl-i"
   },
   "source": [
    "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSeY-MUQo2Ha"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import json as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_data = np.array([['ticker', 'item_type', 'prev_year', 'curr_year', 'similarity_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /Users/kashishgarg/tensorflow_module_cache to cache modules.\n"
     ]
    }
   ],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file 1 section 1A text\n",
    "file = open(\"./data/downloaded_files/AME/2016/AME_0001037868_20161231_Item1A.txt\", \"r\")\n",
    "text1 = file.read()\n",
    "text1Lines = text1.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file 1 section 1A text\n",
    "file = open(\"./data/downloaded_files/AME/2017/AME_0001037868_20171231_Item1A.txt\", \"r\")\n",
    "text2 = file.read()\n",
    "text2Lines = text2.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/kashishgarg/git/similarity_analysis/data/downloaded_files'\n",
    "company_tickers = []\n",
    "# for filename in os.listdir(path):\n",
    "#     company_tickers.append(filename)\n",
    "    \n",
    "company_tickers = [filename for filename in os.listdir(path) if filename != '.DS_Store']\n",
    "\n",
    "company_sections_dict = {}\n",
    "for company in company_tickers:\n",
    "    item1_dict = {}\n",
    "    item1a_dict = {}\n",
    "    item7_dict = {}\n",
    "    item7a_dict = {}\n",
    "    company_file_path = path + '/' + company\n",
    "    years = [filename for filename in os.listdir(company_file_path) if filename != '.DS_Store']\n",
    "    for report_year in years:\n",
    "        section_file_path = company_file_path + '/' + report_year\n",
    "        for filename in os.listdir(section_file_path):\n",
    "            if('Item1A' in filename):\n",
    "                item1a_dict[report_year] = open(section_file_path + '/' + filename, \"r\").read()\n",
    "            elif ('Item1' in filename):\n",
    "                item1_dict[report_year] = open(section_file_path + '/' + filename, \"r\").read()\n",
    "            elif ('Item7A' in filename):\n",
    "                item7a_dict[report_year] = open(section_file_path + '/' + filename, \"r\").read()\n",
    "            elif ('Item7' in filename):\n",
    "                item7_dict[report_year] = open(section_file_path + '/' + filename, \"r\").read()\n",
    "    company_sections_dict[company] = {'item1': item1_dict, 'item1a': item1a_dict, 'item7': item7_dict, 'item7a': item7a_dict}\n",
    "# df = pd.DataFrame.from_dict(company_sections_dict, orient='columns')\n",
    "# df = pd.DataFrame.from_dict({(i,j): company_sections_dict[i][j] \n",
    "#                            for i in company_sections_dict.keys() \n",
    "#                            for j in company_sections_dict[i].keys()},\n",
    "#                        orient='columns')\n",
    "df = pd.DataFrame(company_sections_dict).stack().apply(pd.Series).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "# For evaluation we use exactly normalized rather than\n",
    "# approximately normalized.\n",
    "sts_encode1 = tf.nn.l2_normalize(embed(sts_input1), axis=1)\n",
    "sts_encode2 = tf.nn.l2_normalize(embed(sts_input2), axis=1)\n",
    "cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "clip_cosine_similarities = tf.clip_by_value(cosine_similarities, -1.0, 1.0)\n",
    "sim_scores = 1.0 - tf.acos(clip_cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_score_path = '/Users/kashishgarg/git/similarity_analysis/data/similarity_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(company_sections_dict.get('AAL').get('item1').get(2007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating similarity for: AAL\n",
      "completed writing similarity scores for: AAL\n",
      "calculating similarity for: AME\n",
      "completed writing similarity scores for: AME\n",
      "calculating similarity for: AON\n",
      "completed writing similarity scores for: AON\n",
      "calculating similarity for: AXP\n",
      "completed writing similarity scores for: AXP\n",
      "calculating similarity for: BAX\n",
      "completed writing similarity scores for: BAX\n",
      "calculating similarity for: BBT\n",
      "completed writing similarity scores for: BBT\n",
      "calculating similarity for: BK\n",
      "completed writing similarity scores for: BK\n",
      "calculating similarity for: BRKB\n",
      "completed writing similarity scores for: BRKB\n",
      "calculating similarity for: C\n",
      "completed writing similarity scores for: C\n",
      "calculating similarity for: CAT\n",
      "completed writing similarity scores for: CAT\n",
      "calculating similarity for: CBS\n",
      "completed writing similarity scores for: CBS\n",
      "calculating similarity for: CCI\n",
      "completed writing similarity scores for: CCI\n",
      "calculating similarity for: CL\n",
      "completed writing similarity scores for: CL\n",
      "calculating similarity for: CSRA\n",
      "completed writing similarity scores for: CSRA\n",
      "calculating similarity for: CSX\n",
      "completed writing similarity scores for: CSX\n",
      "calculating similarity for: DHR\n",
      "completed writing similarity scores for: DHR\n",
      "calculating similarity for: DIS\n",
      "completed writing similarity scores for: DIS\n",
      "calculating similarity for: DRI\n",
      "completed writing similarity scores for: DRI\n",
      "calculating similarity for: DUK\n",
      "completed writing similarity scores for: DUK\n",
      "calculating similarity for: EIX\n",
      "completed writing similarity scores for: EIX\n",
      "calculating similarity for: EQR\n",
      "completed writing similarity scores for: EQR\n",
      "calculating similarity for: ETR\n",
      "completed writing similarity scores for: ETR\n",
      "calculating similarity for: FAST\n",
      "completed writing similarity scores for: FAST\n",
      "calculating similarity for: FDX\n",
      "completed writing similarity scores for: FDX\n",
      "calculating similarity for: FITB\n",
      "completed writing similarity scores for: FITB\n",
      "calculating similarity for: FL\n",
      "completed writing similarity scores for: FL\n",
      "calculating similarity for: FLIR\n",
      "completed writing similarity scores for: FLIR\n",
      "calculating similarity for: FTV\n",
      "completed writing similarity scores for: FTV\n",
      "calculating similarity for: GS\n",
      "completed writing similarity scores for: GS\n",
      "calculating similarity for: HAS\n",
      "completed writing similarity scores for: HAS\n",
      "calculating similarity for: HD\n",
      "completed writing similarity scores for: HD\n",
      "calculating similarity for: HOLX\n",
      "completed writing similarity scores for: HOLX\n",
      "calculating similarity for: IPG\n",
      "completed writing similarity scores for: IPG\n",
      "calculating similarity for: ITW\n",
      "completed writing similarity scores for: ITW\n",
      "calculating similarity for: JEC\n",
      "completed writing similarity scores for: JEC\n",
      "calculating similarity for: JNJ\n",
      "completed writing similarity scores for: JNJ\n",
      "calculating similarity for: JWN\n",
      "completed writing similarity scores for: JWN\n",
      "calculating similarity for: KIM\n",
      "completed writing similarity scores for: KIM\n",
      "calculating similarity for: KMB\n",
      "completed writing similarity scores for: KMB\n",
      "calculating similarity for: LH\n",
      "completed writing similarity scores for: LH\n",
      "calculating similarity for: LLL\n",
      "completed writing similarity scores for: LLL\n",
      "calculating similarity for: LOW\n",
      "completed writing similarity scores for: LOW\n",
      "calculating similarity for: MAT\n",
      "completed writing similarity scores for: MAT\n",
      "calculating similarity for: MCHP\n",
      "completed writing similarity scores for: MCHP\n",
      "calculating similarity for: MKC\n",
      "completed writing similarity scores for: MKC\n",
      "calculating similarity for: MMC\n",
      "completed writing similarity scores for: MMC\n",
      "calculating similarity for: MS\n",
      "completed writing similarity scores for: MS\n",
      "calculating similarity for: MTB\n",
      "completed writing similarity scores for: MTB\n",
      "calculating similarity for: NDAQ\n",
      "completed writing similarity scores for: NDAQ\n",
      "calculating similarity for: NLSN\n",
      "completed writing similarity scores for: NLSN\n",
      "calculating similarity for: NWL\n",
      "completed writing similarity scores for: NWL\n",
      "calculating similarity for: OMC\n",
      "completed writing similarity scores for: OMC\n",
      "calculating similarity for: ORCL\n",
      "completed writing similarity scores for: ORCL\n",
      "calculating similarity for: PDCO\n",
      "completed writing similarity scores for: PDCO\n",
      "calculating similarity for: PEP\n",
      "completed writing similarity scores for: PEP\n",
      "calculating similarity for: PG\n",
      "completed writing similarity scores for: PG\n",
      "calculating similarity for: PH\n",
      "completed writing similarity scores for: PH\n",
      "calculating similarity for: PKI\n",
      "completed writing similarity scores for: PKI\n",
      "calculating similarity for: PSA\n",
      "completed writing similarity scores for: PSA\n",
      "calculating similarity for: PWR\n",
      "completed writing similarity scores for: PWR\n",
      "calculating similarity for: RF\n",
      "completed writing similarity scores for: RF\n",
      "calculating similarity for: ROK\n",
      "completed writing similarity scores for: ROK\n",
      "calculating similarity for: SCG\n",
      "completed writing similarity scores for: SCG\n",
      "calculating similarity for: SHW\n",
      "completed writing similarity scores for: SHW\n",
      "calculating similarity for: SNI\n",
      "completed writing similarity scores for: SNI\n",
      "calculating similarity for: SPG\n",
      "completed writing similarity scores for: SPG\n",
      "calculating similarity for: SYY\n",
      "completed writing similarity scores for: SYY\n",
      "calculating similarity for: TDG\n",
      "completed writing similarity scores for: TDG\n",
      "calculating similarity for: TMK\n",
      "completed writing similarity scores for: TMK\n",
      "calculating similarity for: TSN\n",
      "completed writing similarity scores for: TSN\n",
      "calculating similarity for: TSO\n",
      "completed writing similarity scores for: TSO\n",
      "calculating similarity for: TXN\n",
      "completed writing similarity scores for: TXN\n",
      "calculating similarity for: TXT\n",
      "completed writing similarity scores for: TXT\n",
      "calculating similarity for: UAL\n",
      "completed writing similarity scores for: UAL\n",
      "calculating similarity for: UNP\n",
      "completed writing similarity scores for: UNP\n",
      "calculating similarity for: VNO\n",
      "completed writing similarity scores for: VNO\n",
      "calculating similarity for: WLTW\n",
      "completed writing similarity scores for: WLTW\n",
      "calculating similarity for: WM\n",
      "completed writing similarity scores for: WM\n",
      "calculating similarity for: WY\n",
      "completed writing similarity scores for: WY\n",
      "calculating similarity for: WYNN\n",
      "completed writing similarity scores for: WYNN\n",
      "calculating similarity for: XLNX\n",
      "completed writing similarity scores for: XLNX\n"
     ]
    }
   ],
   "source": [
    "report_years = ['2007','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018']\n",
    "def run_similarity(session, text_across_years):\n",
    "  \"\"\"Returns the similarity scores\"\"\"\n",
    "      \n",
    "  emba, embb, scores = session.run(\n",
    "      [sts_encode1, sts_encode2, sim_scores],\n",
    "      feed_dict={\n",
    "          sts_input1: [text_across_years.get(report_years[i], '') for i in range( len(report_years) -1)],\n",
    "          sts_input2: [text_across_years.get(report_years[i], '') for i in range(1, len(report_years))]\n",
    "      })\n",
    "  scores_list = scores.tolist()\n",
    "  item_similarity = []\n",
    "  for i in range(len(report_years) -1):\n",
    "    if scores_list[i] < 0:\n",
    "        item_similarity.append({report_years[i] + '-' + report_years[i+1]: 0})\n",
    "    elif scores_list[i] > 1:\n",
    "        item_similarity.append({report_years[i] + '-' + report_years[i+1]: 1})\n",
    "    else:\n",
    "        item_similarity.append({report_years[i] + '-' + report_years[i+1]: scores_list[i]})\n",
    "  return item_similarity\n",
    "\n",
    "\n",
    "for company in company_sections_dict.keys():\n",
    "    print(\"calculating similarity for: \" + company)\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        session.run(tf.tables_initializer())\n",
    "        if company_sections_dict.get(company, {}).get('item1') is not None:\n",
    "            item1_similarity = run_similarity(session, company_sections_dict.get(company).get('item1'))\n",
    "        if company_sections_dict.get(company, {}).get('item1a') is not None:\n",
    "            item1a_similarity = run_similarity(session, company_sections_dict.get(company).get('item1a'))\n",
    "        if company_sections_dict.get(company, {}).get('item7') is not None:\n",
    "            item7_similarity = run_similarity(session, company_sections_dict.get(company).get('item7'))\n",
    "        if company_sections_dict.get(company, {}).get('item7a') is not None:\n",
    "            item7a_similarity = run_similarity(session, company_sections_dict.get(company).get('item7a'))\n",
    "        similarity_dict = {'item1': item1_similarity, 'item1a': item1a_similarity, \n",
    "                           'item7': item7_similarity, 'item7a': item7a_similarity}\n",
    "        json_string = json.dumps(similarity_dict)\n",
    "        open(similarity_score_path + '/' + company + '_score.json', 'w').write(json_string)\n",
    "    print('completed writing similarity scores for: ' + company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14230835 -0.11991525 -0.41105306]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size: 512\n",
      "Embedding: [-0.03950010985136032, 0.01821286231279373, 0.0436711348593235, ...]\n",
      "\n",
      "Embedding size: 512\n",
      "Embedding: [-0.034965552389621735, 0.043505389243364334, 0.04279985651373863, ...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Universal Sentence Encoder's TF Hub module\n",
    "# embed = hub.Module(module_url)\n",
    "\n",
    "messages = [text1, text2]\n",
    "\n",
    "# Reduce logging output.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  message_embeddings = session.run(embed(messages))\n",
    "\n",
    "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
    "#     print(\"Message: {}\".format(messages[i]))\n",
    "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
    "    message_embedding_snippet = \", \".join(\n",
    "        (str(x) for x in message_embedding[:3]))\n",
    "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97456092929988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_2007 = np.array(message_embeddings).tolist()[0]\n",
    "embeddings_2008 = np.array(message_embeddings).tolist()[1]\n",
    "np.matmul(embeddings_2007, embeddings_2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_by_line_2007 = np.array(message_embeddings).tolist()[2]\n",
    "# embeddings_by_line_2008 = np.array(message_embeddings).tolist()[3]\n",
    "# np.matmul(embeddings_by_line_2007, embeddings_by_line_2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnlm_module_url = \"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\"\n",
    "nnlm_embed = hub.Module(nnlm_module_url)\n",
    "nnlm_embeddings = nnlm_embed([text1, text2])\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "  nnlm_message_embeddings = session.run(nnlm_embeddings)\n",
    "  print(type(nnlm_message_embeddings))\n",
    "\n",
    "  for i, nnlm_message_embedding in enumerate(np.array(nnlm_message_embeddings).tolist()):\n",
    "#     print(\"Message: {}\".format(messages[i]))\n",
    "    print(\"Embedding size: {}\".format(len(nnlm_message_embedding)))\n",
    "    message_embedding_snippet = \", \".join(\n",
    "        (str(x) for x in nnlm_message_embedding[:3]))\n",
    "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "    \n",
    "mean = np.mean(nnlm_message_embeddings)\n",
    "year1_embedding = np.array(nnlm_message_embeddings/128).tolist()[0]\n",
    "year2_embedding = np.array(nnlm_message_embeddings/128).tolist()[1]\n",
    "print(np.matmul(year1_embedding, year2_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# elmo_module_url = \"https://tfhub.dev/google/elmo/2\"\n",
    "# elmo = hub.Module(elmo_module_url, trainable=False)\n",
    "# elmo_embeddings = elmo(\n",
    "#     [text1, text2])\n",
    "# #     signature=\"default\",\n",
    "# #     as_dict=True)[\"elmo\"]\n",
    "# with tf.Session() as session:\n",
    "#   session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "#   elmo_message_embeddings = session.run(elmo_embeddings)\n",
    "    \n",
    "# for i, elmo_message_embedding in enumerate(np.array(elmo_message_embeddings).tolist()):\n",
    "# #     print(\"Message: {}\".format(messages[i]))\n",
    "#     print(\"Embedding size: {}\".format(len(elmo_message_embedding)))\n",
    "#     message_embedding_snippet = \", \".join(\n",
    "#         (str(x) for x in nnlm_message_embedding[:3]))\n",
    "#     print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnvjATdy64eR"
   },
   "source": [
    "# Semantic Textual Similarity Task Example\n",
    "\n",
    "The embeddings produced by the Universal Sentence Encoder are approximately normalized. The semantic similarity of two sentences can be trivially computed as the inner product of the encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1FFCTKm7ba4"
   },
   "outputs": [],
   "source": [
    "def plot_similarity(labels, features, rotation):\n",
    "  corr = np.inner(features, features)\n",
    "  sns.set(font_scale=1.2)\n",
    "  g = sns.heatmap(\n",
    "      corr,\n",
    "      xticklabels=labels,\n",
    "      yticklabels=labels,\n",
    "      vmin=0,\n",
    "      vmax=1,\n",
    "      cmap=\"YlOrRd\")\n",
    "  g.set_xticklabels(labels, rotation=rotation)\n",
    "  g.set_title(\"Semantic Textual Similarity\")\n",
    "\n",
    "\n",
    "def run_and_plot(session_, input_tensor_, messages_, encoding_tensor):\n",
    "  message_embeddings_ = session_.run(\n",
    "      encoding_tensor, feed_dict={input_tensor_: messages_})\n",
    "  plot_similarity(messages_, message_embeddings_, 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "339tuJ5Pwqqv"
   },
   "source": [
    "## Similarity Visualized\n",
    "Here we show the similarity in a heat map. The final graph is a 9x9 matrix where each entry `[i, j]` is colored based on the inner product of the encodings for sentence `i` and `j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPMCaxrZwp7t"
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # Smartphones\n",
    "    \"I like my phone\",\n",
    "    \"My phone is not good.\",\n",
    "    \"Your cellphone looks great.\",\n",
    "\n",
    "    # Weather\n",
    "    \"Will it snow tomorrow?\",\n",
    "    \"Recently a lot of hurricanes have hit the US\",\n",
    "    \"Global warming is real\",\n",
    "\n",
    "    # Food and health\n",
    "    \"An apple a day, keeps the doctors away\",\n",
    "    \"Eating strawberries is healthy\",\n",
    "    \"Is paleo better than keto?\",\n",
    "\n",
    "    # Asking about age\n",
    "    \"How old are you?\",\n",
    "    \"what is your age?\",\n",
    "]\n",
    "\n",
    "similarity_input_placeholder = tf.placeholder(tf.string, shape=(None))\n",
    "similarity_message_encodings = embed(similarity_input_placeholder)\n",
    "with tf.Session() as session:\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  run_and_plot(session, similarity_input_placeholder, messages,\n",
    "               similarity_message_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FjdeCqPJeg-"
   },
   "source": [
    "## Evaluation: STS (Semantic Textual Similarity) Benchmark\n",
    "\n",
    "The [**STS Benchmark**](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) provides an intristic evaluation of the degree to which similarity scores computed using sentence embeddings align with human judgements. The benchmark requires systems to return similarity scores for a diverse selection of sentence pairs. [Pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) is then used to evaluate the quality of the machine similarity scores against human judgements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5nuBbI1iFQR"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VOs8ZfOnJeBF"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import scipy\n",
    "import math\n",
    "\n",
    "\n",
    "def load_sts_dataset(filename):\n",
    "  # Loads a subset of the STS dataset into a DataFrame. In particular both\n",
    "  # sentences and their human rated similarity score.\n",
    "  sent_pairs = []\n",
    "  with tf.gfile.GFile(filename, \"r\") as f:\n",
    "    for line in f:\n",
    "      ts = line.strip().split(\"\\t\")\n",
    "      # (sent_1, sent_2, similarity_score)\n",
    "      sent_pairs.append((ts[5], ts[6], float(ts[4])))\n",
    "  return pandas.DataFrame(sent_pairs, columns=[\"sent_1\", \"sent_2\", \"sim\"])\n",
    "\n",
    "\n",
    "def download_and_load_sts_data():\n",
    "  sts_dataset = tf.keras.utils.get_file(\n",
    "      fname=\"Stsbenchmark.tar.gz\",\n",
    "      origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
    "      extract=True)\n",
    "\n",
    "  sts_dev = load_sts_dataset(\n",
    "      os.path.join(os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-dev.csv\"))\n",
    "  sts_test = load_sts_dataset(\n",
    "      os.path.join(\n",
    "          os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"))\n",
    "\n",
    "  return sts_dev, sts_test\n",
    "\n",
    "\n",
    "sts_dev, sts_test = download_and_load_sts_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "sts_data = sts_dev\n",
    "print(type(sts_data['sent_1'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MkqPOxH3EL1j"
   },
   "source": [
    "### Build Evaluation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PeoO8z30smCS"
   },
   "outputs": [],
   "source": [
    "sts_input1 = tf.placeholder(tf.string, shape=(None))\n",
    "sts_input2 = tf.placeholder(tf.string, shape=(None))\n",
    "\n",
    "# For evaluation we use exactly normalized rather than\n",
    "# approximately normalized.\n",
    "sts_encode1 = tf.nn.l2_normalize(embed(sts_input1), axis=1)\n",
    "sts_encode2 = tf.nn.l2_normalize(embed(sts_input2), axis=1)\n",
    "cosine_similarities = tf.reduce_sum(tf.multiply(sts_encode1, sts_encode2), axis=1)\n",
    "clip_cosine_similarities = tf.clip_by_value(cosine_similarities, -1.0, 1.0)\n",
    "sim_scores = 1.0 - tf.acos(clip_cosine_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OKy8WhnKRe_"
   },
   "source": [
    "### Evaluate Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5PwUwn0qb2RN"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sts_dev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6c1c31e8432a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msts_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msts_dev\u001b[0m \u001b[0;31m#@param [\"sts_dev\", \"sts_test\"] {type:\"raw\"}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sts_dev' is not defined"
     ]
    }
   ],
   "source": [
    "sts_data = sts_dev #@param [\"sts_dev\", \"sts_test\"] {type:\"raw\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-q2r7jyZGb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8127506  0.7951114  0.6856092  ... 0.02519631 0.08812553 0.29005396]\n",
      "Pearson correlation coefficient = 0.7629205501666685\n",
      "p-value = 4.521539751346317e-286\n"
     ]
    }
   ],
   "source": [
    "text_a = sts_data['sent_1'].tolist()\n",
    "text_b = sts_data['sent_2'].tolist()\n",
    "dev_scores = sts_data['sim'].tolist()\n",
    "\n",
    "def run_sts_benchmark(session):\n",
    "  \"\"\"Returns the similarity scores\"\"\"\n",
    "  emba, embb, scores = session.run(\n",
    "      [sts_encode1, sts_encode2, sim_scores],\n",
    "      feed_dict={\n",
    "          sts_input1: text_a,\n",
    "          sts_input2: text_b\n",
    "      })\n",
    "  return scores\n",
    "\n",
    "\n",
    "with tf.Session() as session:\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  scores = run_sts_benchmark(session)\n",
    "\n",
    "print(scores)\n",
    "pearson_correlation = scipy.stats.pearsonr(scores, dev_scores)\n",
    "print('Pearson correlation coefficient = {0}\\np-value = {1}'.format(\n",
    "    pearson_correlation[0], pearson_correlation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RUymE2l9GZfO"
   ],
   "name": "Copy of Semantic Similarity with TF-Hub Universal Encoder",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb",
     "timestamp": 1535831569190
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
